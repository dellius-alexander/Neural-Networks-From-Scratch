{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Accuracy\n",
    "\n",
    "In this notebook, we will explore `accuracy` of the model. The metric commonly used with `loss` to `optimize` the model is `accuracy`. Accuracy describes how often the largest confidence is the correct class in terms of a fraction. ***The accuracy is calculated as the number of correct predictions divided by the total number of predictions.*** We will use the `argmax` values from the `softmax` outputs and then compare these to the targets. \n",
    "\n",
    "- We will calculate the accuracy of the model on the test data to see how well the model is performing. \n",
    "- We will also calculate the accuracy of the model on the training data to see if the model is overfitting or not. \n",
    "- We will also calculate the accuracy of the model on the validation data to see if the model is generalizing well or not. \n",
    "- We will also calculate the accuracy of the model on the unseen data to see if the model is generalizing well or not. \n",
    "- We will also calculate the accuracy of the model on the seen data to see if the model is generalizing well or not. \n",
    "\n"
   ],
   "id": "f63a094482bcff56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T20:27:02.343749Z",
     "start_time": "2024-09-17T20:27:02.062813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Probabilities of 3 samples\n",
    "softmax_outputs = np.array(\n",
    "    [[0.7, 0.2, 0.1], [0.5, 0.1, 0.4], [0.02, 0.9, 0.08]]\n",
    ")\n",
    "\n",
    "# Target (ground-truth) labels for 3 samples\n",
    "class_targets = np.array([0, 1, 1])\n",
    "\n",
    "# TODO: We are also handling one-hot encoded targets by converting them to sparse values using np.argmax()\n",
    "# Calculate values along second axis (axis of index 1)\n",
    "predictions = np.argmax(softmax_outputs, axis=1)\n",
    "# If targets are one-hot encoded - convert them\n",
    "if len(class_targets.shape) == 2:\n",
    "    class_targets = np.argmax(class_targets, axis=1)\n",
    "# True evaluates to 1; False to 0\n",
    "accuracy = np.mean(predictions == class_targets)\n",
    "print(\"accuracy:\", accuracy)"
   ],
   "id": "a348ec304c163c5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Accuracy of the Model\n",
    "\n",
    "Now, we will calculate the accuracy of the model on the test data to see how well the model is performing. We will use a spiral dataset to test the model."
   ],
   "id": "f12302cc2666497c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now we create a dense layer with 3 neurons with 2 inputs each and 2 dense layers; the first layer has 3 neurons with 2 inputs each and the second layer has 3 neurons with 3 inputs each.\n",
    "from src.layer.dense import Dense\n",
    "from src.utils.datasets import create_spiral_dataset\n",
    "from src.functions.activation import Softmax, ReLU\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# Initialize activation function\n",
    "softmax = Softmax()\n",
    "relu = ReLU()\n",
    "\n",
    "# Create a spiral dataset\n",
    "X, y = create_spiral_dataset(100, 3)\n",
    "y = np.array([y])\n",
    "print(f\"Inputs: {X.shape}\")\n",
    "print(f\"Y is a spiral dataset: {y.shape}\")\n",
    "\n",
    "# Create a dense layer with 3 neurons with 2 inputs each\n",
    "dense = Dense(2, 3)\n",
    "\n",
    "# Lets do the forward pass\n",
    "dense.forward(X)\n",
    "print(f\"Weights Layer 1: {dense.weights.shape}\")\n",
    "print(f\"Biases Layer 1: {dense.biases.shape}\")\n",
    "print(f\"Output Layer 1: {dense.output.shape}\")\n",
    "\n",
    "# Run the activation function ReLU\n",
    "dense_output = relu(dense.output)\n",
    "\n",
    "# Create a dense layer with 3 neurons with 3 inputs each\n",
    "dense2 = Dense(3, 3)\n",
    "\n",
    "# Lets do the forward pass\n",
    "dense2.forward(dense_output)\n",
    "print(f\"Weights Layer 2: {dense2.weights.shape}\")\n",
    "print(f\"Biases Layer 2: {dense2.biases.shape}\")\n",
    "print(f\"Output Layer 2: {dense2.output.shape}\")\n",
    "\n",
    "# TODO: These final outputs are also our “confidence scores.” The higher the confidence score, the more confident the model is that the input belongs to that class.\n",
    "\n",
    "# Run the activation function ReLU\n",
    "predictions = softmax(dense2.output)\n",
    "print(f\"Pre Resize Predictions: {predictions.shape}\")\n",
    "\n",
    "# Match the size of predictions to the size of y\n",
    "# Calculate zoom factor\n",
    "zoom_factor = np.array(y.shape) / np.array(predictions.shape)\n",
    "# Resize the predictions\n",
    "predictions = zoom(\n",
    "    predictions, zoom_factor, order=3\n",
    ")  # 'order=3' for cubic interpolation\n",
    "# predictions = np.array([predictions[range(len(predictions)), y[0]]])\n",
    "print(f\"Post Resize Predictions: {predictions.shape}\")\n",
    "print(f\"True labels shape: {y.shape}\")\n",
    "print(f\"Predictions Data[:1,0]: \\n{predictions[:1,0]}\")\n",
    "\n",
    "# Calculate the loss and print the results to 7 decimal places\n",
    "avg_loss, loss = dense2.loss(predictions, y)\n",
    "print(f\"Loss: {avg_loss:.7f}\")  # Loss: 5.7037784\n",
    "print(f\"Loss Data Shape: \\n{loss.shape}\")\n",
    "\n",
    "# Run ArgMax to get the predicted class\n",
    "# Check the shape of the predictions\n",
    "if len(predictions.shape) == 2:\n",
    "    predictions_class = np.argmax(predictions, axis=0)\n",
    "else:\n",
    "    predictions_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(f\"Predicted Class Shape: {predictions_class.shape}\")\n",
    "print(f\"Predicted Class: {predictions_class[0]}\")\n",
    "\n",
    "# Calculate the accuracy\n",
    "# Check the shape of the ground truth labels\n",
    "# If targets are one-hot encoded - convert them\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y, axis=0)\n",
    "else:\n",
    "    y = np.argmax(y, axis=1)\n",
    "print(f\"Ground Truth Shape: {y.shape}\")\n",
    "print(f\"Ground Truth Class: {y[0]}\")\n",
    "\n",
    "# True evaluates to 1; False to 0\n",
    "accuracy = np.mean(predictions_class == y)\n",
    "print(f\"Accuracy: {accuracy:.7f}\")  # Accuracy: 0.3333333"
   ],
   "id": "da8dd88e9afaa1aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adjusting Weights and Biases\n",
    "\n",
    "Now, we will adjust the weights and biases of the model to improve the accuracy. We will use an iterative loop set to some large epoch value to adjust the weights and biases. We will also calculate the accuracy of the model on the test data to see how well the model is performing. We will use a vertical dataset to test the model.\n"
   ],
   "id": "d36a44575ebd7d3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a dense layer with 3 neurons with 2 inputs each and 2 dense layers; the first layer has 3 neurons with 2 inputs each and the second layer has 3 neurons with 3 inputs each.\n",
    "from src.layer.dense import Dense\n",
    "from src.functions.activation import Softmax, ReLU\n",
    "from scipy.ndimage import zoom\n",
    "from src.utils.datasets import create_vertical_data\n",
    "import numpy as np\n",
    "from src.utils.logger import getLogger\n",
    "\n",
    "# Create a vertical dataset\n",
    "X, y = create_vertical_data(100, 3)\n",
    "y = y.reshape(-1, 1)\n",
    "print(f\"Inputs: {X.shape}\")\n",
    "print(f\"Y is a vertical dataset: {y.shape}\")\n",
    "\n",
    "# Create a dense layer with 3 neurons with 2 inputs each\n",
    "dense = Dense(2, 3)\n",
    "print(f\"Weights Layer 1: {dense.weights.shape}\")\n",
    "print(f\"Biases Layer 1: {dense.biases.shape}\")\n",
    "\n",
    "# Create a dense layer with 3 neurons with 3 inputs each\n",
    "dense2 = Dense(3, 3)\n",
    "print(f\"Weights Layer 2: {dense2.weights.shape}\")\n",
    "print(f\"Biases Layer 2: {dense2.biases.shape}\")\n",
    "\n",
    "# Initialize activation function\n",
    "softmax = Softmax()\n",
    "relu = ReLU()\n",
    "\n",
    "# We will create some variables to track the best loss, accuracy and the associated weights and biases\n",
    "lowest_loss = 9999999\n",
    "best_accuracy = 0\n",
    "best_epoch = 0\n",
    "best_weights = dense.weights.copy()\n",
    "best_biases = dense.biases.copy()\n",
    "best_weights2 = dense2.weights.copy()\n",
    "best_biases2 = dense2.biases.copy()\n",
    "\n",
    "# Set the learning rate\n",
    "# learning_rate = 0.1\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 10000\n",
    "print(f\"Epoch Count: {epochs}\")\n",
    "# Iterate over the epochs\n",
    "for epoch in range(epochs):\n",
    "    # Generate a new set of weights and biases for each iteration\n",
    "    dense.weights = 0.5 * np.random.randn(2, 3)\n",
    "    dense.biases = 0.1 * np.random.randn(1, 3)\n",
    "    dense2.weights = 0.5 * np.random.randn(3, 3)\n",
    "    dense2.biases = 0.1 * np.random.randn(1, 3)\n",
    "    y_copy = y.copy()\n",
    "\n",
    "    # Forward pass\n",
    "    dense.forward(X)\n",
    "    dense.activation = relu(dense.output)\n",
    "    dense2.forward(dense.activation)\n",
    "    predictions = softmax(dense2.output)\n",
    "\n",
    "    # Reshape the ground truth labels if transformed during the forward pass\n",
    "    if len(y_copy.shape) == 1:\n",
    "        y_copy = np.array([y_copy])\n",
    "    elif len(y_copy.shape) > 2:\n",
    "        y_copy = np.array([y_copy]).reshape(-1, 1)\n",
    "\n",
    "    # Match the size of predictions to the size of y\n",
    "    if (y_copy.shape[1], y_copy.shape[0]) != predictions.shape or (\n",
    "        y_copy.shape[0],\n",
    "        y_copy.shape[1],\n",
    "    ) != predictions.shape:\n",
    "        zoom_factor = np.array(y_copy.shape) / np.array(predictions.shape)\n",
    "        predictions = zoom(predictions, zoom_factor, order=3)\n",
    "\n",
    "    # Calculate the loss\n",
    "    avg_loss, loss = dense2.loss(predictions, y_copy)\n",
    "\n",
    "    # One-hot encode the predictions\n",
    "    if len(predictions.shape) >= 2:\n",
    "        predictions_class = np.argmax(predictions, axis=1)\n",
    "    elif len(predictions.shape) == 1:\n",
    "        predictions_class = np.argmax(predictions, axis=0)\n",
    "    else:\n",
    "        predictions_class = np.argmax(predictions)\n",
    "\n",
    "    # One-hot encode the ground truth labels\n",
    "    if len(y_copy.shape) >= 2:\n",
    "        y_copy = np.argmax(y_copy, axis=1)\n",
    "    elif len(y_copy.shape) == 1:\n",
    "        y_copy = np.argmax(y_copy, axis=0)\n",
    "    else:\n",
    "        y_copy = np.argmax(y_copy)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = np.mean(predictions_class == y_copy)\n",
    "\n",
    "    # Check if the loss is lower than the previous lowest loss\n",
    "    # and if the accuracy is higher than the previous best accuracy\n",
    "    if avg_loss < lowest_loss or accuracy > best_accuracy:\n",
    "        print(f\"Epoch: {epoch}, Loss: {avg_loss:.7f}, Accuracy: {accuracy:.7f}\")\n",
    "        best_epoch = epoch\n",
    "        lowest_loss = avg_loss\n",
    "        best_accuracy = accuracy\n",
    "        best_weights = dense.weights.copy()\n",
    "        best_biases = dense.biases.copy()\n",
    "        best_weights2 = dense2.weights.copy()\n",
    "        best_biases2 = dense2.biases.copy()\n",
    "\n",
    "    # Print the best weights and biases when the epoch is complete\n",
    "    if epoch == epochs - 1:\n",
    "        print(f\"Total Epoch Count: {epochs}\")\n",
    "        print(\n",
    "            f\"Best Epoch: {best_epoch}, Best Loss: {lowest_loss:.7f}, Best Accuracy: {best_accuracy:.7f}\"\n",
    "        )\n",
    "        print(f\"Best Weights Layer 1: \\n{best_weights}\")\n",
    "        print(f\"Best Biases Layer 1: \\n{best_biases}\")\n",
    "        print(f\"Best Weights Layer 2: \\n{best_weights2}\")\n",
    "        print(f\"Best Biases Layer 2: \\n{best_biases2}\")"
   ],
   "id": "90b5a315443ae84f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8a4ad8ec6fffead7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
